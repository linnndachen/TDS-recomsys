{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import joblib\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/EA_CSV.csv\", engine=\"python\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn the first row into column\n",
    "def get_data(df):\n",
    "    #combine the description\n",
    "    df['description'] = df['Expertise'].fillna('') + \" \" + df['Title'].fillna('')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(s):\n",
    "    #removeNonAscii\n",
    "    s = \"\".join(i for i in s if ord(i)<128)\n",
    "\n",
    "    #return all lower cases\n",
    "    s = s.lower()\n",
    "\n",
    "    #remove stop wrods\n",
    "    s = s.split()\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in s if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "\n",
    "    #remove html\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    text = html_pattern.sub(r'', text)\n",
    "\n",
    "    #remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]',\" \",text)\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove_model(file_path='glove.twitter.27B.200d.txt'):\n",
    "  \"\"\"\n",
    "  input: the access to the file which contains the pre-trained glove model\n",
    "  ouput: a trained model using glove\n",
    "  \"\"\"\n",
    "\n",
    "  embeddings_index = {}\n",
    "  f = open(file_path, encoding='utf-8')\n",
    "  for line in f:\n",
    "      values = line.split()\n",
    "      word = values[0]\n",
    "      coefs = np.asarray(values[1:], dtype='float32')\n",
    "      embeddings_index[word] = coefs\n",
    "  f.close()\n",
    "  return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove2vec(text, model):\n",
    "    \"\"\"\n",
    "    input: \n",
    "    - text: the string that you wanted to turn into vectors\n",
    "    - model: the glove pre-trained model that you wanted to use\n",
    "\n",
    "    output:\n",
    "    an average vector of your input text using the glove model\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Creating a list for storing the vectors (description into vectors)\n",
    "    global word_embeddings\n",
    "    word_embeddings = []\n",
    "\n",
    "    vectors = {}\n",
    "\n",
    "    avgword2vec = None\n",
    "    count = 0\n",
    "\n",
    "    for word in text.split():\n",
    "        if word in model:\n",
    "            count += 1\n",
    "            if avgword2vec is None:\n",
    "                avgword2vec = model[word]\n",
    "            else:\n",
    "                avgword2vec = avgword2vec + model[word]\n",
    "            \n",
    "    if avgword2vec is not None:\n",
    "        avgword2vec = avgword2vec / count\n",
    "    \n",
    "    word_embeddings.append(avgword2vec)\n",
    "\n",
    "    return word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendations_glove(input, df=df, col='description'):\n",
    "    \"\"\"\n",
    "    input: \n",
    "    - input: key words relating to the article\n",
    "    - df: the dataframe that we are using\n",
    "    - col: the column name that contains description of EAs\n",
    "    - file path: the file path to the pre-trained glove model\n",
    "\n",
    "    output:\n",
    "    a list of EAs' names ranked by the most recommended / most suitable EA\n",
    "    to the least\n",
    "    \"\"\"\n",
    "\n",
    "    #get the model (it is too slow to compute the model every time)\n",
    "    model = glove_model(file_path='glove.twitter.27B.200d.txt')\n",
    "\n",
    "    # vecterizd the input\n",
    "    vector_input = glove2vec(input, model)\n",
    "\n",
    "    # vecterized all the descriptions of EAs\n",
    "    df[col] = df[col].apply(clean_text)\n",
    "    EAs_vectors = [glove2vec(EA, model) for EA in df[col]]\n",
    "\n",
    "    #drop an EA if that EA has \"None\" vector\n",
    "    df['vectors'] = EAs_vectors\n",
    "    for i, n in enumerate(df['vectors']):\n",
    "      if n[0] is None:\n",
    "        df = df.drop([i+1], axis=0)\n",
    "\n",
    "\n",
    "    # finding cosine similarity for the vectors\n",
    "    similarity = []\n",
    "    for n in df['vectors']:\n",
    "      scores = cosine_similarity(vector_input, n)[0][0]\n",
    "      similarity.append(scores)\n",
    "    \n",
    "    df['similarity'] = similarity\n",
    "\n",
    "\n",
    "    # sort and find the recommended movie\n",
    "    df = df.sort_values(by=['similarity'], ascending=False)\n",
    "    #res_df = df.iloc[:m]\n",
    "\n",
    "\n",
    "    return df['Names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_vec(input, model):\n",
    "    avgword2vec = None\n",
    "    count = 0\n",
    "    for word in input.split():\n",
    "        if word in model:\n",
    "            count += 1\n",
    "            if avgword2vec is None:\n",
    "                avgword2vec = model[word]\n",
    "            else:\n",
    "                avgword2vec = avgword2vec + model[word]\n",
    "\n",
    "    if avgword2vec is not None:\n",
    "        avgword2vec = avgword2vec / count\n",
    "\n",
    "    return avgword2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vec(keywords, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomm_engine(keywords, vec_df, model):\n",
    "    \"\"\"\n",
    "    assummed we directly import vecterized EA information and trained model.\n",
    "    \"\"\"\n",
    "    # vectorize the input\n",
    "    cleaned_input = clean_text(keywords)\n",
    "    input_vector = input_vec(cleaned_input, model)\n",
    "\n",
    "    # finding cosine similarity for the vectors\n",
    "    similarity = []\n",
    "    input_vector = input_vector.reshape(1,-1)\n",
    "    for n in vec_df['vectors']:\n",
    "        n = n.reshape(1,-1)\n",
    "        scores = cosine_similarity(input_vector, n)[0][0]\n",
    "        similarity.append(scores)\n",
    "\n",
    "    vec_df['similarity'] = similarity\n",
    "\n",
    "    # sort and find the recommended movie\n",
    "    vec_df = vec_df.sort_values(by=['similarity'], ascending=False)\n",
    "\n",
    "    return vec_df.loc[::, :'Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_df = pd.read_pickle('models/vectors.pkl')\n",
    "\n",
    "model = joblib.load('models/glove_model.pkl')\n",
    "keywords = 'data collection, data ethics issues/initial assumptions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recomm_engine(keywords, vec_df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}